# Contributing to AATMF

Thank you for your interest in contributing to the Adversarial AI Threat Modeling Framework! This framework helps security researchers, red teamers, and organizations defend against AI-specific attacks.

## How You Can Contribute

### 1. Adding New Techniques

Discovered a new AI attack technique? Here's how to add it:

**Step 1: Fork the Repository**
- Click "Fork" in the top-right corner
- Clone your fork: `git clone https://github.com/YOUR-USERNAME/AATMF-Adversarial-AI-Threat-Modeling-Framework.git`

**Step 2: Create Technique File**
- Navigate to the appropriate tactic folder: `docs/vol-2-core-tactics/`
- Create a new technique file following our naming convention:
  - Format: `T[tactic-number].[technique-number]-[technique-name].md`
  - Example: `T01.017-context-window-overflow.md`

**Step 3: Use the Technique Template**
```markdown
# T[X].[XXX] - [Technique Name]

## Description
[Clear explanation of the attack technique]

## Attack Vector
- **Target:** [What AI component this attacks]
- **Prerequisites:** [What attacker needs]
- **Complexity:** [Low/Medium/High]

## Real-World Example
[Concrete example with actual LLM or AI system]

## Detection
[How to detect this attack]

## Mitigation
[How to defend against this attack]

## References
- [Link to research paper]
- [Link to CVE or disclosure]
```

**Step 4: Submit Pull Request**
- Commit with clear message: `Add T01.017: Context Window Overflow technique`
- Push to your fork
- Create PR with description explaining the technique and why it matters

### 2. Reporting Issues

**Found an error?**
- Technique description unclear ‚Üí Open "Documentation" issue
- Gap in framework coverage ‚Üí Open "Enhancement" issue  
- Real-world attack not covered ‚Üí Open "New Technique" issue

**Template for New Technique Issues:**
```
Title: [Technique Name] - [Tactic] Attack

Description: [What the attack does]
Target System: [LLM API / Agentic AI / RAG system / etc.]
Real-World Impact: [Link to disclosure, paper, or incident]
Suggested Tactic: T[number] - [Tactic name]
```

### 3. Sharing Case Studies

Used AATMF in a real security assessment?

- Open an issue titled "Case Study: [Organization Type]"  
- Share (anonymized):
  - Which techniques were most effective
  - What you discovered
  - How defenders responded
- We'll feature case studies in documentation

### 4. Improving Documentation

- Fix typos or unclear explanations
- Add code examples for attack techniques
- Translate content (let us know which language)
- Create video walkthroughs

## Contribution Guidelines

### Quality Standards

**For New Techniques:**
- ‚úÖ Must include real-world example or PoC
- ‚úÖ Must provide both detection and mitigation guidance
- ‚úÖ Must cite sources (research papers, CVEs, disclosures)
- ‚ùå No theoretical attacks without proof-of-concept
- ‚ùå No duplicate techniques (search existing first)

**For Documentation:**
- ‚úÖ Clear, concise language
- ‚úÖ Code examples where applicable
- ‚úÖ Proper markdown formatting
- ‚úÖ Links to official sources

### Code of Conduct

- **Responsible Disclosure:** If documenting zero-days, follow responsible disclosure
- **No Malicious Use:** Contributions must improve defensive capabilities
- **Respectful:** Be professional in issues and PRs
- **Attribution:** Credit original researchers when documenting their work

## Recognition

All contributors will be:
- ‚ú® Listed in CONTRIBUTORS.md
- ‚ú® Acknowledged in framework release notes
- ‚ú® Credited in presentations and papers using AATMF
- ‚ú® Recognized in the OWASP GenAI Security Project

## Questions?

- **General questions:** Open a GitHub Discussion
- **Security concerns:** Email kai@snailsploit.com
- **Framework usage:** Check [Quick Start Guide](README.md#quick-start)

## License

By contributing, you agree that your contributions will be licensed under CC BY-SA 4.0.

---

**Ready to contribute?** Start by:
1. ‚≠ê Starring this repository
2. üìñ Reading the [framework documentation](docs/)
3. üîç Checking [existing issues](https://github.com/SnailSploit/AATMF-Adversarial-AI-Threat-Modeling-Framework/issues)
4. üí° Opening your first issue or PR

Thank you for helping secure AI systems! üõ°Ô∏è
